## 2.23 论文总结
* [cs.DB] [**Efficient Filtered-ANN via Learning-based Query Planning**](https://arxiv.org/pdf/2602.17914)
  * [ANNS & Query Optimization] 过滤式近似最近邻搜索中，预过滤需为不同谓词构建专属索引，计算成本高；后过滤易因选择性低导致召回损失且存在冗余计算，单一执行策略无法适配所有查询场景。针对该问题，本文提出基于学习的查询规划框架，核心设计为两步式决策流程：先通过轻量级选择性估计器，结合预计算统计信息分别对分类、数值范围及混合谓词做精准选择性预测；再训练双层MLP分类器作为核心规划器，依据数据集统计特征和估计选择性，为每个查询动态选择预过滤或后过滤策略。该框架兼容各类ANN索引与过滤类型，无需GPU且推理开销极低。实验结果表明，在ArXiv、SIFT等数据集上，框架召回率保持≥90%的同时实现最高4×加速，索引构建成本较ACORN-1降低20.24×，显著优于传统固定策略与现有过滤式ANN方法。

* [cs.DB] [**From Lossy to Verified: A Provenance-Aware Tiered Memory for Agents**](https://arxiv.org/abs/2602.17913)
  * [Agent Memory & Provenance] 长视野智能体的历史压缩存在**写前查询壁垒**，压缩决策早于未来查询需求，易丢失关键约束导致答案无法验证；而保留原始日志虽能保证溯源性，但会带来高昂的token消耗与推理延迟。本文提出TierMem溯源感知的分层内存框架，核心创新为基于证据充分性的检索机制：设计快速摘要索引与不可变原始日志存储两层内存结构，默认从摘要索引查询，通过运行时充分性路由器，仅在摘要证据不足时升级至原始日志；同时将验证后的结果作为新摘要单元写回，并关联其原始溯源。实验在LoCoMo数据集上验证，该框架准确率达0.851（接近原始日志的0.873），输入token消耗减少54.1%，推理延迟降低60.7%，实现验证性与效率的平衡。

* [cs.DB] [**Multi-Attribute Group Fairness in k-NN Queries on Vector Databases**](https://arxiv.org/abs/2602.17858)
  * [ANNS & Fairness] 向量数据库k近邻查询的多属性组公平性研究存在空白，现有方法仅关注检索效率或单属性过滤，无法同时满足多个受保护属性的比例表示约束，且多属性公平性约束下的查询问题计算复杂度高。本文提出多属性组公平的k-NN查询框架，核心设计为：适配局部敏感哈希（LSH）加速候选生成，为受保护属性的笛卡尔积构建轻量级索引，快速检索满足联合计数约束的候选集；设计后处理阶段构建跨所有属性的公平k近邻结果，针对2个属性提出多项式时间的流基精确算法，针对3个及以上属性设计整数线性规划（ILP）精确解法。该框架提供理论性能保证，明确了效率-公平性的权衡关系。实验表明，现有向量检索方法无法直接适配公平性需求，而该框架具备良好的通用性与可扩展性，在保证检索质量的同时满足多属性公平约束。

* [cs.DC] [**Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs**](https://arxiv.org/abs/2602.17808)
  * [Edge Inference & Multi-Tenant Optimization] 内存受限的边缘TPU多租户推理场景中，存在租户间资源竞争、内存利用率低、推理延迟高等核心问题，现有单机推理方法未考虑多租户的协同处理策略，无法适配边缘设备的资源约束。针对该问题，本文聚焦边缘TPU的多租户推理协同处理优化，核心围绕租户间的资源调度、内存共享、计算任务拆分展开设计，通过构建协同处理架构，实现边缘TPU内存资源的精细化分配与计算任务的并行调度，缓解多租户资源竞争，提升整体推理吞吐量与资源利用率。该方法针对性解决边缘设备内存受限的痛点，适配物联网、边缘智能等实际多租户推理场景。

* [cs.CL] [**Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention**](https://arxiv.org/abs/2602.18145)
  * [LLM Hallucination Detection] 大语言模型的上下文幻觉检测面临两大挑战：幻觉内容与上下文存在浅层语义关联，难以通过简单语义匹配识别；现有方法忽略token的上下文频率特征，无法区分模型生成的真实关联内容与虚假幻觉内容。本文提出基于频率感知注意力的上下文幻觉检测方法，核心设计为：挖掘token在上下文窗口中的频率分布特征，构建频率感知的注意力权重计算机制，强化低频率关键上下文token的注意力聚焦，弱化模型生成的无频率支撑的幻觉token；设计幻觉检测分类器，结合频率感知注意力特征与语义特征，实现对上下文幻觉的精准识别。该方法无需额外微调，可无缝集成至现有LLM，有效提升幻觉检测的准确率，降低漏检与误检率。

* [cs.CL] [**Sink-Aware Pruning for Diffusion Language Models**](https://arxiv.org/abs/2602.17664)
  * [Diffusion LLM & Pruning Optimization] 扩散语言模型的剪枝方法直接沿用自回归LLM的注意力锚点保留策略，但扩散模型的注意力锚点位置在生成轨迹中方差极高，锚点具有瞬时性，并非结构必需，盲目保留会造成计算冗余，影响剪枝效率。针对该问题，本文提出锚点感知剪枝（Sink-Aware Pruning）方法，核心创新为：通过量化生成轨迹中注意力锚点的位置方差，自动识别扩散模型中的不稳定锚点；对不稳定锚点进行针对性剪枝，保留真正的结构关键节点，打破自回归模型的剪枝思维定式。该方法无需重新训练，在匹配计算量的前提下，实现了更优的生成质量-效率权衡，显著优于现有扩散模型剪枝基线，有效降低扩散语言模型的推理成本。